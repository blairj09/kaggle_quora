---
title: "EDA"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r setup}
# Load libraries
require(data.table)
require(magrittr)
require(tidyverse)
require(tidytext)
require(h2o)
require(feather)
```

```{r load data}
# Data is preprocessed using the script pre_processing.R

# Raw training data
train <- read_feather("../data/train.feather")

# Tidy data - all train data and 100000 samples from test data
tidy_data <- read_feather("../data/tidy_data.feather") %>% 
  as.data.table

# Tidy train
tidy_train <- read_feather("../data/tidy_train.feather") %>% 
  as.data.table

# Training data response column
train_response <- read_feather("../data/train_responses.feather") %>% 
  as.data.table

# Column classes
sapply(tidy_data, class)
```

# Data Exploration
```{r}
# Preview of raw training data
head(train, 20)

# Unique qids in train
length(unique(c(train$qid1, train$qid2)))

# How many times do different ids appear?
table(c(train$qid1, train$qid2)) %>% 
  as.data.table %>% 
  .[,.N, by = N]

# How many ids appear in both locations?
sum(train$qid1 %in% train$qid2)
```

```{r}
# Distribution of words per question
question_word_count <- tidy_data[,.N, by = .(question_num, id, data)][order(data, id)]
question_word_count[which.max(N)]

question_word_count[,.N, by = .(count = N, data)][,p := N/sum(N), by = data] %>% 
  filter(count < 50) %>%
  ggplot(aes(x = count, y = p, fill = data)) +
  geom_col(position = "dodge") +
  theme_minimal() +
  labs(title = "Word Count Distribution",
       x = "Word Count",
       y = "Proportion")

# Distribution of differences in word count between question pairs
question_wc_diff <- question_word_count %>% 
  dcast(id + data ~ question_num, value.var = "N") %>%
  mutate(diff = abs(question2 - question1)) %>% 
  as.data.table

question_wc_diff[,.(count = .N), by = .(diff, data)][,p := count/sum(count), by = data] %>% 
  filter(diff < 50) %>% 
  ggplot(aes(x = diff, y = p, fill = data)) +
  geom_col(position = "dodge") +
  theme_minimal()


# Distribution of characters per question


```

An important question here is what makes two questions the same? Questions are the same if the *main idea* is the same, even if the phrasing changes. The algorithm needs to be able to pick up on the *main idea* of each question and determine how much they overlap.

## Pre Processing
### Spelling correction
### Remove stop words
### Remove special characters

# Feature Engineering
## Possible features
The following is a list of features that may be helptful to incorportate:
* Shared words
* Sentiment of each question
* Shared words weighted by importance
* Shared subject
* word2vec features - what if all text is thrown into a copus and passed through word2vec? Numerical similarities could be computed for each question using the vector embeddings for each word - how far is the center of this sentence from the center of that sentence?
* Question format - what type of question is used (why, how, what, etc)

## Shared words
Calculate the number of shared words between the two questions
```{r}
# Calculate scaled shared words
shared_words <- tidy_train[,.(shared_words = sum(word[question_num == "question1"] %in% word[question_num == "question2"])/(.N/2)),
             by = id]

# Join shared words back into training data
train %<>% merge(shared_words,
                 by = "id")

# Explore relationship between shared words and question matches
train %>% 
  ggplot(aes(x = is_duplicate, y = shared_words)) +
  geom_boxplot() +
  theme_minimal()
```

## Question format
Determine if the two questions have the same question key word (who, what when, where, why, how)
```{r}
question_words <- c(
  "who",
  "what",
  "when",
  "where",
  "why"
)

common_question <- tidy_train[,.(common_question = any(intersect(question_words,
                                          word[question_num == "question1"]) %in% 
                word[question_num=="question2"])),
           by = id]

train %<>% merge(common_question,
                 by = "id")

# Plot relationship
train[,.(common_question = mean(common_question)),
      by = is_duplicate] %>% 
  ggplot(aes(x = is_duplicate, y = common_question)) +
  geom_col() +
  theme_minimal()
```

## WC difference
Determine if the difference in word count between two questions is a strong signal of similarity
```{r}
train %<>% merge(question_wc_diff[,.(id, wc_diff = diff)],
                 by = "id",
                 all.x = TRUE) %>% 
  as.data.table

train[wc_diff < 25] %>% 
  ggplot(aes(x = is_duplicate, y = wc_diff)) +
  geom_boxplot() +
  theme_minimal()
```

## TF IDF
The question to consider with this approach is what to consider a document - all train vs all test? Duplicates vs non duplicates? Worth exploring several options here
```{r}
tf_idf_values <- tidy_data %>% 
  count(data, word, sort = TRUE) %>% 
  ungroup %>% 
  bind_tf_idf(word, data, n) %>% 
  as.data.table

tidy_data %<>% merge(tf_idf_values[,.(data, word, tf_idf)],
                 by = c("word", "data"),
                 all.x = TRUE)

# Calculate score based on tf_idf values
```
